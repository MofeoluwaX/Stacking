{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking is basically using the predictions from different models to train another model.\n",
    "The models whose predictions are used are called level0 models or base models.\n",
    "The model which is then trained on the predictions of previous models is known as level1 model or the meta model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two methods:\n",
    "    1. Using Sklearn stacking classifier class \n",
    "    2. Building yours\n",
    "    \n",
    "Which ever method, you're doing the same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a common practise to use very strong models like GBMs, tree models, NN as your level0 models and use a simple linear model such as LogisticRegressor/ LinearRegressor as the case maybe as your level1 models beacuse it'a believed that linear models know the best way to combine these predictions and give an out put result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demonstration, our level0 models will be: Catboost and LightGBM and our level1 model will be Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in our data (i'd be using the dsn qualification data set)\n",
    "i'll need to quickly preprocess the data, you can skip that part, i'll do all that in just one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df= pd.read_csv('../DATA/Train.csv')\n",
    "\n",
    "df.drop('Applicant_ID', 1, inplace= True)\n",
    "\n",
    "y= df.default_status.map({'yes': 1, 'no': 0})\n",
    "df.drop(['default_status'], 1, inplace= True)\n",
    "df= pd.get_dummies(df, drop_first= True)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cols= df.columns\n",
    "pipe= Pipeline([('imputer', SimpleImputer(strategy= 'mean')), ('scaler', StandardScaler())])\n",
    "X= to_df(pipe.fit_transform(df), cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the models we'd be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 (Using stacking classifier)\n",
    "\n",
    "It takes in three major parameters  \n",
    "\n",
    "\n",
    "`estimators`: These are the base models, you pass them in as list of tuples cintaing the name and the model itself e.g   \n",
    "[('cat', CatBoostClassifier()), ('lgb',LGBMClassifier())]\n",
    "\n",
    "\n",
    "`final_estimator`: this is the meta model it is passed in normally e.g LogisticRegression()\n",
    "\n",
    "\n",
    "`passthrough`: It takes in True or False, True means the features of the data set should also be passed in while training the meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8083928571428571"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "level0 = [('cat', CatBoostClassifier(n_estimators= 100, silent= True)), ('lgb',LGBMClassifier(n_estimators= 100))]\n",
    "level1= LogisticRegression()\n",
    "\n",
    "stack= StackingClassifier(estimators= level0, final_estimator=level1, passthrough= False, verbose= 0)\n",
    "# Now train Logistic regression using this new data\n",
    "\n",
    "stack.fit(X_train, y_train)\n",
    "stack.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 (Building our stacking classifier)\n",
    "\n",
    "Four steps\n",
    "1. Train your base models\n",
    "2. Get the prediction from the models\n",
    "3. Turn them to a data frame\n",
    "4. Train the meta model with the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8084821428571428"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb= LGBMClassifier(n_estimators= 100)\n",
    "lgb.fit(X_train, y_train)\n",
    "lgb_pred= lgb.predict_proba(X_test)[:, 1]\n",
    "lgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8014285714285714"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat= CatBoostClassifier(n_estimators= 100, silent=True)\n",
    "cat.fit(X_train, y_train)\n",
    "cat_pred= cat.predict_proba(X_test)[:, 1]\n",
    "cat.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.102562</td>\n",
       "      <td>0.100558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.523367</td>\n",
       "      <td>0.534773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.169679</td>\n",
       "      <td>0.104345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007308</td>\n",
       "      <td>0.014864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.359594</td>\n",
       "      <td>0.369882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lgb       cat\n",
       "0  0.102562  0.100558\n",
       "1  0.523367  0.534773\n",
       "2  0.169679  0.104345\n",
       "3  0.007308  0.014864\n",
       "4  0.359594  0.369882"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Form a dataframe with the predictions\n",
    "stacked= pd.DataFrame({'lgb': lgb_pred, 'cat': cat_pred})\n",
    "stacked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8010714285714285"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now train Logistic regression using this new data\n",
    "lr= LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reasons there's no obvious (maybe because we only ran 100 estimators)improvement, but that's the idea sha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
